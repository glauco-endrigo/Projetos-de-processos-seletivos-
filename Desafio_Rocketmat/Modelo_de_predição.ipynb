{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Modelo de predição <br />\n",
    "\n",
    "## Sumário:\n",
    "\n",
    "   ## 1. Introdução\n",
    "      1.1  Objetivo \n",
    "      1.2  Bibliotecas\n",
    "      \n",
    "   ## 2. Dados \n",
    "      2.1 Ler os dados\n",
    "      2.2 Ler os dados pré-processados:\n",
    "      2.3 Separando os dados :\n",
    "       \n",
    "   ## 3. Pré-processadores\n",
    "      3.1 Criando o pré-processador\n",
    "      3.2 Funções de limpeza de dados testadas:\n",
    "      3.3 Funções de padronização e normalização testadas:\n",
    "      3.4 Funções para encoding:\n",
    "       \n",
    "   ## 4.  Fluxo de processos com Pipeline:\n",
    "      4.1 Modelos de classificação testados  \n",
    "          4.11  K Nearest Neighbors\n",
    "          4.12  Support Vector Machine\n",
    "          4.13  Árvore de decisão\n",
    "          4.14  Regressão logística\n",
    "      4.2 Pipeline\n",
    "      4.3 Dicionário de pipelines\n",
    "       \n",
    "       \n",
    "   ## 5. Validação cruzada: Avaliando o desempenho do estimador\n",
    "   \n",
    "   ## 6. Ajuste fino de parâmetros:\n",
    "       \n",
    "      6.1 Parâmetros dos modelos de Machine Learning\n",
    "      6.2 Aplicando a técnica Grid search\n",
    "       \n",
    "   ## 7. Seleção de Features\n",
    "      7.1 Definindo o melhor k para a função de seleção de Features: SelectKBest()\n",
    "      7.2 Gráficos de K vs mean absolute error (MAE)\n",
    "      7.3 Adicionando a função SelectKBest() ao Pipeline\n",
    "       \n",
    "   ## 8.  Persistindo os modelos para o disco\n",
    "   \n",
    "   ## 9.  Verificando quais funcionários valiosos sairão da empresa:\n",
    "       \n",
    "      9.1 Filtro: Melhores funcionários\n",
    "      9.2 Modelo escolhido para a solução\n",
    "      9.3 Importância das Features\n",
    "      9.4 Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução\n",
    "\n",
    "#### 1.1 Objetivo:\n",
    "* Verificar quais funcionários valiosos sairão da empresa.\n",
    "\n",
    "#### 1.2  Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from __Pre_Processamento__.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb            # Permite \"importar\"  outros arquivos  ipynb \n",
    "import os                      # Para criar Diretórios\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from sklearn                   import neighbors   \n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.preprocessing     import OneHotEncoder, StandardScaler, MaxAbsScaler\n",
    "from sklearn.neighbors         import KNeighborsClassifier\n",
    "from sklearn.linear_model      import LogisticRegression\n",
    "from sklearn.tree              import DecisionTreeClassifier\n",
    "from sklearn.impute            import SimpleImputer\n",
    "from sklearn.compose           import ColumnTransformer\n",
    "from sklearn.model_selection   import GridSearchCV\n",
    "\n",
    "from joblib import dump, load  # Persistir os modelos para o disco\n",
    "\n",
    "# Módulos que eu criei \n",
    "import __Pre_Processamento__\n",
    "from   __Pre_Processamento__   import Pre_Processamento_inicial, Separar\n",
    "\n",
    "# Seleção de Features:\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn.compose           import make_column_transformer\n",
    "from sklearn.metrics           import mean_absolute_error\n",
    "\n",
    "#Gráficos\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dados\n",
    "\n",
    "#### 2.1 Ler os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"HR_Engagement_Sat_Sales_UpdatedV4.0.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Ler os dados pré-processados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ler  = Pre_Processamento_inicial(dados, Premissas_1 = True)\n",
    "dados_processados_inicialmente = dados_ler.dados_processados_inicialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Separando os dados :\n",
    "\n",
    "O médodo \"separando\" da classe \"Separar()\" permite separar  os dados de acordo com a estrutura que o modelo ML exige, ou seja,  X = features e y target.                                                 \n",
    "Os dados categóricos e contínuos podem ser separados usando as propriedades do método \"separando\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sep =  Separar()                                                # Instanciando  a classe \n",
    "Sep.separando(\"left_Company\", dados_processados_inicialmente)   # separando(\"Target\", dados)\n",
    "X = Sep.X # Features \n",
    "y = Sep.y # Target\n",
    "\n",
    "# Propriedades do método separando - Separando dados categóricos e contínuos.\n",
    "categorical_features =  Sep.Colunas_dados_categoricos           # dados categóricos\n",
    "numeric_features     =  Sep.Colunas_dados_numericos             # dados contínuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Pré-processadores\n",
    "\n",
    "#### 3.1 Criando o  pré-processador\n",
    "\n",
    "* O Scikit-learn a partir da versão 0.20 fornece  a função  sklearn.compose.ColumnTransformer para fazer o transformador de coluna com tipos mistos. Pode-se escalar  as features  numéricas e codificar as categóricos no mesmo processo.\n",
    "* Cuidado: este método é EXPERIMENTAL, alguns comportamentos podem mudar entre os lançamentos sem depreciação.\n",
    "\n",
    "#### 3.2 Funções de limpeza de dados testadas: \n",
    "   3.21  SimpleImputer(): \n",
    "   Tratar  dados faltantes utilizando a classe SimpleImputer da biblioteca sklearn.impute.Lembrando que já foi realizado um tratamento inicial de dados faltantes, de acordo  com as premissas iniciais.\n",
    "\n",
    "#### 3.3 Funções de padronização e normalização testadas: \n",
    "\n",
    "3.31 StandardScaler() \n",
    "   * Eficiente para features com distribuição   normal.\n",
    "   * Para cada feature, o StandardScaler()  dimensiona os valores de forma que a média seja 0 e o desvio padrão seja 1 (ou a variância).\n",
    "   * O StandardScaler assume que a distribuição da variável é normal. Assim, caso as variáveis não sejam normalmente distribuídas, pode-se : \n",
    "        * Escolher um dimensionador diferente\n",
    "        * Converter as variáveis para uma distribuição normal e, em seguida, aplicar  o StandardScaler\n",
    "\n",
    "3.32 MaxAbsScaler() \n",
    "   * Pega o valor máximo absoluto de cada coluna e divide cada valor na coluna pelo valor máximo.\n",
    "\n",
    "   * Primeiro obtém-se o valor absoluto de cada valor na coluna e, em seguida, obtém o valor máximo. \n",
    "      Esta operação dimensiona os dados entre o intervalo [-1, 1].\n",
    "\n",
    "3.33 MinMaxScaler() \n",
    "   * O dimensionador MinMax é um dos dimensionadores mais simples de entender. Ele apenas dimensiona todos os dados entre 0       e 1.\n",
    " \n",
    "####  3.4 Funções para encoding:\n",
    "\n",
    "3.41 One-Hot Encoding:\n",
    "\n",
    "   * A variável categórica não é ordinal.\n",
    "   * O número de recursos categóricos é menor, então a codificação one-hot pode ser aplicada com eficácia\n",
    "\n",
    "\n",
    "3.42 Aplicamos a codificação de Label Encoding quando:\n",
    "\n",
    "   * A variável categórica é ordinal ('ruim', 'médio', 'bom')\n",
    "   * O número de categorias é bastante grande, pois a codificação one-hot pode levar a um alto consumo de memória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_1 = ColumnTransformer(\n",
    " transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_2 = Pipeline(steps=\n",
    "      [\n",
    "     (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")\n",
    "     )])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fluxo de processos com Pipeline:\n",
    "O objetivo das  pipelines é reunir várias etapas que podem ser validadas em conjunto ao se definir parâmetros diferentes.\n",
    "\n",
    "Pelas característica do problema, vemos que é um problema para Aprendizagem de Máquina Supervisionada.\n",
    "Devido a natureza dos dados e o fato da variável de predição ser discreta\n",
    "\n",
    "#### 4.1 Modelos de classificação testados :  \n",
    "\n",
    "#### 4.1.1  K Nearest Neighbors\n",
    "    4.1.1.1  É automaticamente não linear, pode detectar dados distribuídos lineares ou não lineares, tende a ter um desempenho muito bom com muitos pontos de dados.\n",
    "\n",
    "    4.1.1.2  Precisa ser cuidadosamente ajustado, a escolha de K e a métrica (distância) a ser usada são críticas.  para muitos pontos de dados, o KNN tem problemas de desempenho. \n",
    "\n",
    "    4.1.1.3  É muito sensível a recursos ruins (atributos), portanto a seleção de recursos também é importante. O KNN também é sensível a valores discrepantes e a remoção deles antes de usá-lo tende a melhorar os resultados.\n",
    "    \n",
    "    \n",
    "#### 4.1.2  Support Vector Machine\n",
    "\n",
    "    4.1.2.1  O SVM pode ser usado de maneiras lineares ou não lineares com o uso de um Kernel, quando se tem um conjunto limitado de pontos em muitas dimensões, o SVM tende a ser muito bom porque deve ser capaz de encontrar a separação linear que possivelmente  existe. \n",
    "    \n",
    "    4.1.2.2  É bom para outliers, pois usará apenas os pontos mais relevantes para encontrar uma separação linear (vetores de suporte)\n",
    "\n",
    "    4.1.2.3  Precisa ser ajustado, o custo \"C\" e o uso de um kernel e  hiperparâmetros são  críticos para o algoritmo. \n",
    "\n",
    "#### 4.1.3  Árvore de decisão\n",
    "\n",
    "Algumas vantagens: \n",
    "\n",
    "    4.1.3.1  Útil em exploração de dados: A árvore de decisão é uma das formas mais rápidas de identificar as variáveis mais   significativas e a relação entre duas ou mais variáveis. Com a ajuda de árvores de decisão, podemos criar novas variáveis/características que tenham melhores condições de predizer a variável alvo. \n",
    "    \n",
    "    4.1.3.2  Menor necessidade de limpar dados: Requer menos limpeza de dados em comparação com outras técnicas de modelagem. Até um certo nível, não é influenciado por pontos fora da curva “outliers” nem por valores faltantes (“missing values”).\n",
    "    \n",
    "    4.1.3.3  Não é restrito por tipos de dados: Pode manipular variáveis numéricas e categóricas.\n",
    "    \n",
    "    4.1.3.4  Método não paramétrico: A árvore de decisão é considerada um método não-paramétrico. Isto significa que as árvores de decisão não pressupõe a distribuição do espaço nem a estrutura do classificador.\n",
    "\n",
    "Algumas desvantagens:\n",
    "\n",
    "    4.1.3.5  Sobreajuste (“Over fitting”): Sobreajuste é uma das maiores dificuldades para os modelos de árvores de decisão. \n",
    "    \n",
    "    4.1.3.6  Não adequado para variáveis contínuas: ao trabalhar com variáveis numéricas contínuas, a árvore de decisão perde informações quando categoriza variáveis em diferentes categorias.\n",
    "    \n",
    "    4.1.3.7  Decision-trees can handle categorical values very well but most of the algorithms expect numerical values to achieve state-of-the-art results.\n",
    "    \n",
    "    4.1.3.8 A codificação Label Encoding  converte dados categóricos para inteiros e o DecisionTreeClassifier() tratará como dados numéricos. Se seus dados categóricos não forem ordinais, isso não é bom - pode ocorrer divisões que não fazem sentido.\n",
    "  \n",
    "    4.1.3.9 A codificação one-hot pode degradar seriamente o desempenho do modelo de árvore\n",
    " \n",
    "#### 4.1.4  Regressão logística\n",
    "\n",
    "    4.1.4.1  A regressão logística é o método usado para problemas de classificação binária (problemas com dois valores de classe), utilizando conceitos de estatística e probabilidade\n",
    "    \n",
    "    4.1.4.2  A documentação de sklearn.linear_model.LogisticRegression mostra que o primeiro parâmetro é:\n",
    "    Penalidade: str, 'l1' ou 'l2', padrão: 'l2' - Usado para especificar a norma usada na penalização. Os solvers ‘newton-cg’, ‘sag’ e ‘lbfgs’ suportam apenas 12 penalidades.\n",
    "    A regularização torna o modelo dependente da escala das features. Recomendada-se  normalizar as features ao fazer regressão logística com regularização. Os autores do livro Elements of  Statistical Learning recomendam o uso do StandardScaler().\n",
    "\n",
    "Algumas vantagens: \n",
    "    \n",
    "    4.1.4.3  A regressão logística é um dos algoritmos de aprendizado de máquina mais simples e é fácil de implementar,fornece grande eficiência.Por esses motivos, treinar um modelo com esse algoritmo não requer alto poder de computação.\n",
    "\n",
    "    4.1.4.4  A regressão logística produz resultados de em termos de probabilidades. Esta é uma vantagem sobre os modelos que fornecem apenas a classificação final como resultado. \n",
    "\n",
    "Algumas desvantagens:\n",
    "\n",
    "    4.1.4.5  A regressão logística requer moderada ou nenhuma multicolinearidade entre as variáveis independentes. Isso significa que se duas variáveis independentes têm uma correlação alta, apenas uma delas deve ser usada. A repetição de informações pode levar ao treinamento incorreto de parâmetros (pesos) durante a minimização da função de custo. A multicolinearidade pode ser removida usando técnicas de redução de dimensionalidade.\n",
    "\n",
    "    4.1.4.6  Apenas features importantes e relevantes devem ser usadas para construir o modelo, caso contrário, as previsões probabilísticas feitas pelo modelo podem estar incorretas e o valor preditivo do modelo pode degradar.\n",
    "\n",
    "\n",
    "Entre o SVM e KNN: \n",
    "\n",
    "-  Muitos pontos em um espaço de baixa dimensão, o KNN provavelmente é uma boa escolha.\n",
    "\n",
    "-  Alguns pontos em um espaço dimensional alto, provavelmente um SVM linear é melhor.\n",
    "\n",
    "Como na base de dados os espaços dimensionais tem bastante pontos,  o Support Vector Machine demoraria muito para rodar na máquina que estou usando. Os demais foram todos testados.\n",
    "\n",
    "#### 4.2 Pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pip_1 = Pipeline([\n",
    "              ('preprocessor_1', preprocessor_1)       \n",
    "             ,(\"knn\" , KNeighborsClassifier(n_neighbors=8))                        # Foi realizado ajuste fino de parâmetros:\n",
    "             \n",
    "             ])\n",
    "\n",
    "logreg_pip_1 = Pipeline([\n",
    "              ('preprocessor_2',preprocessor_2)                                    # [4.1.4.5, 4.1.4.2]\n",
    "             ,(\"logreg\" , LogisticRegression(C=0.1, max_iter = 2000))              # Foi realizado ajuste fino de parâmetros:\n",
    "             ])\n",
    "\n",
    "tree_pip_1 = Pipeline([\n",
    "              ('preprocessor_1',preprocessor_1)\n",
    "             ,(\"tree\" , DecisionTreeClassifier(criterion='entropy', max_depth= 12)) # Foi realizado ajuste fino de parâmetros:\n",
    "             ])\n",
    "Pipelines = [knn_pip_1, logreg_pip_1 , tree_pip_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Dicionário de pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {\n",
    "                        ' knn_pip_1'   : knn_pip_1\n",
    "                        ,'tree_pip_1'  : tree_pip_1\n",
    "                        ,'logreg_pip_1': logreg_pip_1\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validação cruzada: Avaliando o desempenho do estimador\n",
    "* Criando um conjunto de treinamento e  mantendo 20% dos dados para testar (avaliar) nosso classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ajuste fino de parâmetros: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao avaliar diferentes configurações (\"hiperparâmetros\") para estimadores, não se deve ajustar os parãmetros manualmente, isso pode gerar overfitting.Os parâmetros podem acabar sendo  ajustados até que o estimador tenha um desempenho ideal. \n",
    "\n",
    "Para resolver este problema, separa-se um  \"conjunto de validação\": o treinamento é feito no  conjunto de treinamento, após isso  a avaliação é feita no conjunto de validação, e quando o experimento for  bem sucedido , a avaliação final será  feita no conjunto de teste.\n",
    "\n",
    "No entanto, ao particionar os dados disponíveis em três conjuntos, reduzimos drasticamente o número de amostras que podem ser usadas para o modelo.\n",
    "\n",
    "A solução é usar a  técnica \"grid search\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Parâmetros dos modelos de Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Quanto maior for max_depth, maior será o número de divisões na árvore de decisão, e portanto, mais informação o modelo captura dos dados\n",
    "# max_depth não pode ser muito alto pois pode gerar superajuste  modelo \n",
    "max_depth = [10,12,14,16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convenção  = '<named_step>__<parameter>':value \n",
    "param_grid_knn   = {'knn__n_neighbors': np.arange(4, 20,1)}\n",
    "param_grid_LR    = {\"logreg__C\":np.logspace(-1,1,7)}# l1 lasso l2 ridge , \"logreg__penalty\":[\"l1\",\"l2\"]\n",
    "param_grid_tree  = {\"tree__criterion\" :criterion, \"tree__max_depth\":max_depth }\n",
    "\n",
    "\n",
    "param_grid = [param_grid_knn, param_grid_LR, param_grid_tree]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Aplicando a técnica Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score  pip_1 = 0.9581333111037011\n",
      "best_params pip_1 = {'knn__n_neighbors': 8}\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "best_score  pip_2 = 0.9284660886962322\n",
      "best_params pip_2 = {'logreg__C': 0.1}\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "best_score  pip_3 = 0.8862666666666665\n",
      "best_params pip_3 = {'tree__criterion': 'gini', 'tree__max_depth': 10}\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, pip in enumerate(Pipelines):\n",
    "    \n",
    "    grid = GridSearchCV(pip, param_grid[i] , cv=5, scoring = \"accuracy\")\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print('best_score  pip_{} = {}'. format(i+1, grid.best_score_))\n",
    "    print('best_params pip_{} = {}'. format(i+1, grid.best_params_))\n",
    "    print(125*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Seleção de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Definindo o melhor k para a função de seleção de Features: SelectKBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#odelo_selec = logreg_pip_1                # Modelo usado para Seleção de Features \n",
    "modelo_selec  = tree_pip_1                 # Falta automatizar essa parte do código  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processador = modelo_selec.steps[0][1] # Chamando o pré-processador da PipeLine\n",
    "X_2 = pre_processador.fit_transform(X)     # Fit_transform: O fit salva o modelo de pré-processador \n",
    "                                           # O transform vai aplicar o pré-processador e criar um array X_2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape                                  # Verificando  as dimensões de x para definir o range de k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Seleção de Features\n",
    "\n",
    "k_vs_score = []                            # lista para ser usada na\n",
    "suporte    = []                            # lista para ser usada na\n",
    "score_list = []                            # lista para ser usada na\n",
    "\n",
    "#for k in range(2500, 3000,50):\n",
    "for k in range(10, 49,1):    \n",
    "    score_list   = {}                      #Dicionário {k:mean_absolute_error}\n",
    "    score_media  = []\n",
    "    \n",
    "    # Estrutura de loop\n",
    "    # Esse loop tem a função de diminuir um pouco a variação nos resultados de mean_absolute_error.\n",
    "    # Funciona pois a função split está dentro do loop.\n",
    "    for i in range(1,10):\n",
    "        \n",
    "        #Criando um conjunto de treinamento e mantendo 20% dos dados para testar (avaliar) o melhor k:\n",
    "        #Esse segundo split serve unicamente para o propósito  do cálculo de k \n",
    "        X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2,y, test_size= 0.2) \n",
    "        \n",
    "        # Esse método seleciona as k features mais correlacionadas com o alvo \n",
    "        selector = SelectKBest(score_func = f_classif, k = k ) \n",
    "\n",
    "        # fit_transform: O fit faz o cálculo das correlações e armazena no objeto selector \n",
    "        # e o transform vai criar um array só com as melhores k colunas \n",
    "        X_train_new = selector.fit_transform(X_train_2, y_train_2)\n",
    "        X_test_new  = selector.transform(X_test_2)\n",
    "\n",
    "\n",
    "        modelo_selec.steps[1][1].fit(X_train_new,  y_train_2)\n",
    "        Predict_Selec = modelo_selec.steps[1][1].predict(X_test_new)\n",
    "        \n",
    "        \n",
    "        #MAE (mean absolut error): calcula o \"erro absoluto médio\" dos erros entre valores observados (reais) e predições (hipóteses).\n",
    "        score_ = mean_absolute_error(y_test_2, Predict_Selec)\n",
    "        score_list[k] = (score_)               #Dicionário {k:score_} \n",
    "        \n",
    "    score_media.append(score_list[k])          # Salvando os valores do índice k\n",
    "   \n",
    "    score_m = sum(score_media)/len(score_media)# Cáculo da média \n",
    "    k_vs_score.append(score_m)                 # Salvando os mean_absolute_error médios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2  Gráficos de K vs mean absolute error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x225a2ec53d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.plot(range(10, 49,1), k_vs_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Para a  pipeline logreg_pip_1, o k escolhido por inspeção gráfica será 2800 \n",
    " * Para as pipelines  knn_pip_1 e tree_pip_1, o k escolhido por inspeção gráfica será 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Adicionando a função  SelectKBest() ao Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(Pipelines):\n",
    "    \n",
    "    # Estrutura condicional:\n",
    "    # Pré-Processadores diferentes podem gerar  a matriz de  feature \"X\"  com quantidades  diferentes  de colunas.\n",
    "    # Logo, o valor de k também muda \n",
    "    if model.steps[0][0] == \"preprocessor_1\":\n",
    "        k = 48\n",
    "    elif model.steps[0][0] == \"preprocessor_2\":\n",
    "        k = 2800 \n",
    "\n",
    "    # Adicionando a função SelectKBest() ao Pipeline\n",
    "    model.steps.insert(1,['SelectKBest', SelectKBest(score_func = f_classif, k = 48 )]) #inserir no 2º passo da Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Persistindo  os modelos  para o disco:\n",
    "* Resultados usando os  parâmetros otimizados, sem usar a função Grid Search\n",
    "* Persistência dos modelos com Joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo   knn_pip_1 já foi salvo anteriormente\n",
      "Score\t0.9623333333333334\n",
      "O modelo  tree_pip_1 já foi salvo anteriormente\n",
      "Score\t0.9933333333333333\n",
      "O modelo  logreg_pip_1 já foi salvo anteriormente\n",
      "Score\t0.945\n"
     ]
    }
   ],
   "source": [
    "for name, model in classification_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Persistindo os resultados  para o disco: \n",
    "    if not os.path.exists('{}.joblib'.format(name)):\n",
    "        dump(model, '{}.joblib'.format(name))\n",
    "        print(\"O modelo \"+ name +\" foi salvo com sucesso !\")\n",
    "    else:\n",
    "        print(\"O modelo  \" + name + \" já foi salvo anteriormente\")\n",
    "        \n",
    "    print('Score\\t{}'.format( model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verificando quais funcionários valiosos sairão da empresa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Filtro: Melhores funcionários:\n",
    "* Melhores funcionários de acordo com a métrica  \"last_evaluation\".  Foi aplicado o filtro  [\"last_evaluation\"> = 0.87] para definir os melhores  funcionários.Esse valor foi obtido apartir da análise estatística. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filtro_melhores_funcionarios(df):\n",
    "    X_new = df[df[\"left_Company\"]!=1]                 #Tirando os que já sairam, queremos prever o que ocorrerá com os que ainda estão na empresa\n",
    "    X_new = X_new[X_new[\"last_evaluation\"]>=0.870000] # Separando os melhores funcionários.\n",
    "    X_new = X_new.drop(columns = \"left_Company\")      # Preparando os dados para o modelo de Machine Learning \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = Filtro_melhores_funcionarios(dados_processados_inicialmente)  # Dados dos melhores funcionários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Modelo escolhido para a solução:\n",
    "O modelo escolhido foi o de regressão logística, pois  busca-se respostas em termos de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('logreg_pip_1.joblib')                                     # Carregando os dados persistidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3  Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = (clf.predict_proba(X_new))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Obs:\n",
    "A função predict_proba () retorna um array numpy de duas colunas.\n",
    "A primeira coluna é a probabilidade de que alvo = 0 e a segunda coluna é a probabilidade de que alvo = 1.\n",
    "É por isso que adicionamos [:, 1] depois de predict_proba () para obter as probabilidades de alvo = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new[\"probabilidade_de_sair\"] = resultado                              # acrescentando a solução ao X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['probabilidade_de_sair.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solucao = (X_new[\"probabilidade_de_sair\"]).sort_values(ascending=False) # Colocando a resposta em ordem decrescente. \n",
    "dump(solucao, 'probabilidade_de_sair.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4 Solução:\n",
    "* Melhores funcionários de acordo com a métrica  \"last_evaluation\".  Foi aplicado o filtro  [\"last_evaluation\"> = 0.87] para definir os melhores  funcionários.Esse valor foi obtido apartir da análise estatística. \n",
    "* Os resultados indicam as probabilidades de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "11270    0.930213\n",
       "12077    0.866904\n",
       "11308    0.756495\n",
       "13532    0.725005\n",
       "13283    0.710506\n",
       "11665    0.704853\n",
       "12467    0.699241\n",
       "12369    0.684611\n",
       "11373    0.668930\n",
       "11828    0.634668\n",
       "14319    0.593065\n",
       "11427    0.584484\n",
       "14554    0.578534\n",
       "14368    0.527817\n",
       "14024    0.521074\n",
       "12066    0.446229\n",
       "11561    0.395535\n",
       "14643    0.385875\n",
       "11358    0.380550\n",
       "12401    0.373675\n",
       "Name: probabilidade_de_sair, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solucao.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Referências \n",
    "https://iq.opengenus.org/advantages-and-disadvantages-of-logistic-regression/\n",
    "\n",
    "https://www.mariofilho.com/as-metricas-mais-populares-para-avaliar-modelos-de-machine-learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
